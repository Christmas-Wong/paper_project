{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    BertConfig,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    default_data_collator,\n",
    "    DataCollatorWithPadding,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "DIR = \"E:/datasets/hotel_comment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3ff479c2ba161dd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:\\Users\\chris\\.cache\\huggingface\\datasets\\json\\default-3ff479c2ba161dd9\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "412375ffc3d646a0a0c36a4ae6d88ebb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2eacf49d0514c1aa87ea12a975c82c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:\\Users\\chris\\.cache\\huggingface\\datasets\\json\\default-3ff479c2ba161dd9\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a669c481fcf4e5ea059245f3876f7ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 6212\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1553\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\n",
    "        \"train\": os.path.join(DIR, \"trainl.json\"),\n",
    "        \"test\": os.path.join(DIR, \"testl.json\"),\n",
    "    }\n",
    ")\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'不好': 0, '好': 1}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = dataset[\"train\"].unique(\"label\")\n",
    "label_list.sort()  # Let's sort it for determinism\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# label_2_id\n",
    "label_2_id = dict()\n",
    "id_2_label = dict()\n",
    "for index, ele in enumerate(label_list):\n",
    "    label_2_id[ele] = index\n",
    "    id_2_label[index] = ele\n",
    "label_2_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file E:\\pretrained_moel\\chinese-bert-wwm-ext\\added_tokens.json. We won't load it.\n",
      "Didn't find file E:\\pretrained_moel\\chinese-bert-wwm-ext\\special_tokens_map.json. We won't load it.\n",
      "Didn't find file E:\\pretrained_moel\\chinese-bert-wwm-ext\\tokenizer_config.json. We won't load it.\n",
      "loading file E:\\pretrained_moel\\chinese-bert-wwm-ext\\vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file E:\\pretrained_moel\\chinese-bert-wwm-ext\\tokenizer.json\n",
      "loading configuration file E:\\pretrained_moel\\chinese-bert-wwm-ext\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"E:\\\\pretrained_moel\\\\chinese-bert-wwm-ext\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading configuration file E:\\pretrained_moel\\chinese-bert-wwm-ext\\config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.14.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file E:\\pretrained_moel\\chinese-bert-wwm-ext\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at E:\\pretrained_moel\\chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at E:\\pretrained_moel\\chinese-bert-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"E:\\\\pretrained_moel\\\\chinese-bert-wwm-ext\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL)\n",
    "bert_config = BertConfig.from_pretrained(MODEL, num_labels=num_labels)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL, config=bert_config)\n",
    "model.config.label2id = label_2_id\n",
    "model.config.id2label = id_2_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/7 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ae886c3672242859c89d086678fb624"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running tokenizer on dataset:   0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d9a1324ebdf42f9adfbeab00dbdfa32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    result = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Map labels to IDs\n",
    "    result[\"label\"] = [(label_2_id[item] if item != -1 else -1) for item in examples[\"label\"]]\n",
    "    return result\n",
    "\n",
    "raw_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    report = classification_report(\n",
    "        y_true=labels,\n",
    "        y_pred=pred,\n",
    "        output_dict=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"f1\": report[\"macro avg\"][\"f1-score\"]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
    "training_args = TrainingArguments(\n",
    "    f\"confident_learing\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,  # train arguments\n",
    "    train_dataset=raw_datasets[\"train\"],  # train dataset\n",
    "    eval_dataset=raw_datasets[\"test\"],  # evaluate datasets\n",
    "    compute_metrics=compute_metrics,  # compute metric when evaluate\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # early stopping\n",
    "    data_collator=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 6212\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3900\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/3900 : < :, Epoch 0.01/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1553\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to confident_learing\\checkpoint-195\n",
      "Configuration saved in confident_learing\\checkpoint-195\\config.json\n",
      "Model weights saved in confident_learing\\checkpoint-195\\pytorch_model.bin\n",
      "tokenizer config file saved in confident_learing\\checkpoint-195\\tokenizer_config.json\n",
      "Special tokens file saved in confident_learing\\checkpoint-195\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1553\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to confident_learing\\checkpoint-390\n",
      "Configuration saved in confident_learing\\checkpoint-390\\config.json\n",
      "Model weights saved in confident_learing\\checkpoint-390\\pytorch_model.bin\n",
      "tokenizer config file saved in confident_learing\\checkpoint-390\\tokenizer_config.json\n",
      "Special tokens file saved in confident_learing\\checkpoint-390\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1553\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to confident_learing\\checkpoint-585\n",
      "Configuration saved in confident_learing\\checkpoint-585\\config.json\n",
      "Model weights saved in confident_learing\\checkpoint-585\\pytorch_model.bin\n",
      "tokenizer config file saved in confident_learing\\checkpoint-585\\tokenizer_config.json\n",
      "Special tokens file saved in confident_learing\\checkpoint-585\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1553\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to confident_learing\\checkpoint-780\n",
      "Configuration saved in confident_learing\\checkpoint-780\\config.json\n",
      "Model weights saved in confident_learing\\checkpoint-780\\pytorch_model.bin\n",
      "tokenizer config file saved in confident_learing\\checkpoint-780\\tokenizer_config.json\n",
      "Special tokens file saved in confident_learing\\checkpoint-780\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1553\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to confident_learing\\checkpoint-975\n",
      "Configuration saved in confident_learing\\checkpoint-975\\config.json\n",
      "Model weights saved in confident_learing\\checkpoint-975\\pytorch_model.bin\n",
      "tokenizer config file saved in confident_learing\\checkpoint-975\\tokenizer_config.json\n",
      "Special tokens file saved in confident_learing\\checkpoint-975\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from confident_learing\\checkpoint-390 (score: 0.2076723426580429).\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=975, training_loss=0.1627717785957532, metrics={'train_runtime': 136.3001, 'train_samples_per_second': 911.518, 'train_steps_per_second': 28.613, 'total_flos': 2043057344870400.0, 'train_loss': 0.1627717785957532, 'epoch': 5.0})"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def jsonl_reader(file: str) -> list:\n",
    "    \"\"\"Get Json_list from jsonl File\n",
    "\n",
    "    :param file: JSONL file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    result = list()\n",
    "    with codecs.open(file, \"r\", encoding=\"utf_8\") as f:\n",
    "        for line in f.readlines():\n",
    "            json_ele = json.loads(line)\n",
    "            result.append(json_ele)\n",
    "    f.close()\n",
    "    return result\n",
    "\n",
    "list_test = jsonl_reader(\n",
    "    os.path.join(\n",
    "        DIR,\n",
    "        \"testl.json\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': '不好', 'score': 0.005702445283532143}, {'label': '好', 'score': 0.9942975640296936}], [{'label': '不好', 'score': 0.990449845790863}, {'label': '好', 'score': 0.009550112299621105}], [{'label': '不好', 'score': 0.0070745195262134075}, {'label': '好', 'score': 0.9929255247116089}]]\n"
     ]
    }
   ],
   "source": [
    "classifer = TextClassificationPipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    return_all_scores = True,\n",
    "    device=0\n",
    ")\n",
    "list_text = [ele[\"text\"][-510:] for ele in list_test]\n",
    "list_scores = classifer(list_text)\n",
    "print(list_scores[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Number of Test_Dataset is 1553 and there are 58 bad data in Test_Dataset which accounts for 3.734707018673535 %\n",
      "[ 965 1184  987   62  296  369  338 1415   46  940 1302 1249   72 1499\n",
      "   87  654  191  153  924  184  819  631  776  316  782 1008 1526   92\n",
      " 1194  872 1386  446 1019   60  669  313 1070  880  103 1349  458  716\n",
      " 1054  343 1165   93  956  637  498  938  655 1539 1131 1158  983 1208\n",
      " 1331  214]\n"
     ]
    }
   ],
   "source": [
    "import cleanlab\n",
    "s = [label_2_id[ele[\"label\"]] for ele in list_test]\n",
    "psx = list()\n",
    "for ele in list_scores:\n",
    "    psx.append([\n",
    "        ele[0][\"score\"],\n",
    "        ele[1][\"score\"],\n",
    "    ])\n",
    "\n",
    "# Method 5：C+NR\n",
    "cl_both = cleanlab.pruning.get_noise_indices(\n",
    "    np.array(s),\n",
    "    np.array(psx),\n",
    "    prune_method='both',\n",
    "    sorted_index_method='prob_given_label'\n",
    ")\n",
    "print(\n",
    "      \"The total Number of Test_Dataset is {} and there are {} bad data in Test_Dataset which accounts for {} %\".format(\n",
    "          len(list_test),\n",
    "          len(cl_both),\n",
    "          len(cl_both)*100/len(list_test)\n",
    "\n",
    "))\n",
    "print(cl_both)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '打车太不方便，我在门口等了40分钟；早餐品种少。宽带还比较快！房间空调调不了。苏州还有一个茉莉花假日，下次试试。补充点评2008年4月22日：刚接到酒店预订部的电话，对所提的意见进行了跟踪反馈，赞一个。与我14日入住的上海华港雅阁酒店（虹桥机场）比起来，真是天壤之别。24日又到苏州，不过这次我已经预订了另外一家酒店，下次到苏州，我会考虑再次入住友联。希望真的已经改进。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.008587555028498173}, {'label': '好', 'score': 0.9914124011993408}]\n",
      "{'text': '卫生间门是坏的，面巾纸也没有，房间内也不暖和，服务更不怎么样，还比不上当地4星的酒店，特别是前台和礼宾。住了就不想再住', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.988831102848053}, {'label': '好', 'score': 0.011168954893946648}]\n",
      "{'text': '传说中的四星挂牌，2星标准，倒也恰当。房间的地毯确实很脏，其他还行啦！卫生纸确实如传说中的少，两个人有点不够用。服务嘛，不知道，因为是跟携程团去的，一大早就走了，没机会领略。早餐，确实品种少，除了牛奶（是奶粉加糖价开水，亲眼所见）和粥，该冷的是冷的，该热的也还是冷的。稍微晚去就排队加排队。酒店周围都是卖土特产，水果店和小便利店（杂货店）也多。补充点评2007年10月22日：客房提供的居然不是袋泡茶，而是新鲜的绿茶，感觉很好。没有咖啡，有需要的得自带。没有免费矿泉水。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.011512244120240211}, {'label': '好', 'score': 0.9884877800941467}]\n",
      "{'text': '感觉环境,服务方面还不够位,房间里面的洗浴设施有点发黄,需要改善!!', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.014473974704742432}, {'label': '好', 'score': 0.9855259656906128}]\n",
      "{'text': '已经是第三次入住该酒店了，虽然换了一些新床和桌椅，但还是越来越久了．无论是服务还是其他，也就只有一星而已．只是在南戴河的话没办法了．', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.015065353363752365}, {'label': '好', 'score': 0.9849346876144409}]\n",
      "{'text': '设施太旧了,服务也不行,打电话要个插座都推来推去,给四星太勉强了.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9847245812416077}, {'label': '好', 'score': 0.015275351703166962}]\n",
      "{'text': '10月24日入住西楼,房间很宽敞,但设施旧了一些,它的房间有两道门,这点很少见,所以晚上很安静,走廊的声音会小很多.当时相同的价格,如果去附近的步行街上找一找,会有惊喜.还好,电视信号还有,那天嫦娥升空,真巧.', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.015326425433158875}, {'label': '好', 'score': 0.9846735000610352}]\n",
      "{'text': '差就一个字！房间隔音差，马路上的声音声声入耳！所谓的宽带还没有拨号上网快，打开网页要等半天，收邮件整整收了5个小时才收下来！跟前台反映问题说没有办法解决！', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9845486879348755}, {'label': '好', 'score': 0.015451296232640743}]\n",
      "{'text': '一般情况下我不会对酒店评价，但这个酒店实在是需要点评一下，非常不满意。主要有以下情况：1.前台给我的房间是D座，从前台到客房走了5分多钟，对于5星级实在不敢恭维。2.进入客房非常冷，打开空调半个小时左右才热起来。3.空调声音巨大，晚上开空调睡不着，不开又冷，只能凑合了。4.5星饭店居然没有电熨斗和熨衣板，我也懒得和客房要，实在说不过去。5.饭店里居然没有ATM机。6.饭店门口没有出租车，到大门等的话，由于此饭店在鄂尔多斯市郊，打车很难。7.客房的冰箱里居然连付费的饮料都没有，但有个饮料单，呵呵。8.卫生间居然没有浴缸，倒不是一定要泡澡，但5星的标准实在值得怀疑。9.淋浴室的角落都是脏的，很难想象发生过什么，呵呵。10.没有看到饭店服务介绍的资料，只有一个点评单，我都懒得评了，实在没什么可说的。总的说，饭店的硬件还OK,服务人员的服务还可以，但小的问题太多，性价比实在太低。希望改进。改进前我是不会再住此饭店了。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9837054014205933}, {'label': '好', 'score': 0.01629459485411644}]\n",
      "{'text': '和山里的农庄比算是好的了吧。墙壁都开裂了，房间还算干净，离镇上有1公里吧，叫车只要2元。镇上有上海华联，还挺大的，买些吃的喝的用的都挺方便。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.01765650138258934}, {'label': '好', 'score': 0.9823434352874756}]\n",
      "{'text': '非常一般，房间很小，家具过时、老旧。性价比太差，订一晚，后又续一晚。实在不满意后俩日改住洲际酒店。我后面续订一日，居然不算通过携城预定！可能是利益所驱，相较之下，洲际我也是先订一日再续。洲际就处理的很好。补充点评2008年5月20日：还有，通过携城订的是大床房，去了变成标间。非常不愉快！', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9768576622009277}, {'label': '好', 'score': 0.02314228191971779}]\n",
      "{'text': '除了地段好之外，其他没有一样好的。宽带慢得像蜗牛，他们居然说就是这样。大堂和客房是在不同楼里，我登记后要拿行李出门去旁边的楼坐电梯。早餐也配五星酒店？吃得像农村一样。以后不会住的。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9757274389266968}, {'label': '好', 'score': 0.024272583425045013}]\n",
      "{'text': '注意啦！！这个酒店只有6、7楼重新装修过（地毯是深灰色）。其他都是旧装修。我们出住时，提出要看房间，前台安排我们看了6楼。是不错的装修。地毯是新的。没有什么异味。但5楼是该酒店的KTV，很吵。但5楼的房里能听到楼下唱歌及微微的震动。所以我决定不选五楼。我问服务员，这房间是新装修的吗？因为看到洗手间的配置很新。他回答我不是，全酒店都一样。回到前台，他们给我安排了13楼。心想不错嘛。结果与朋友拖着行李到了13楼，电梯一开，已看到是旧地毯，污积斑斑。进了房间，一鼓酸臭味！洗手间也不是5楼的配置。。。差异太大了。结果，，我们做了有史以来最经典的事。。。因错按了一层号码，电梯门一开，发现也是旧装修（旧地毯，浅色大花）补充点评2007年10月10日：结果，我们决定每一层都看一下地毯来决定来入住哪一层，因我10.1期间自驾车去玩，共入住过6晚不同的酒店，前一天入住[杭州]杭州最佳西方梅苑宾馆，就是因为只相信了CTRIP的网评，在没有看房间的情况下入住了，房间感觉很不好，根本与四星不相配，所以这次一定要选好一点。我们坐电梯每一层都看了一眼地毯（当时已晚上10点，没有什么客人来往，所以我们不会打扰到其他人用电梯，而且有4台电梯的）发现只有7楼是新地毯，还是11楼及15楼是比较干净的旧款地毯（主要是霉气味不太重。来到前台要求换房，转7楼或11楼。前台也不说什么，同意换。但告之：7楼已客满。11楼是行政楼层，要加100元。最后，我们选了15楼。。要求非吸烟房。前台同意。进房，，还是有点霉气味，但比11楼小。最好笑就是看到服务员从房间里拿走烟灰缸，，哈哈！！！这就是非吸烟房！！服务员给我们打开窗户，说吹一下风，味道就没有了。天呀！！四星酒店！！！真是只有6楼的配置比较合符四星。。但5楼的噪音又将此优势给去掉了。。。但酒店对面另一家“皇冠”酒店也是四星的。比它更不好，所以，还是住下了。。这间酒店是唯一一间要退房时，查有没有东西要赔，之类的。。我前几天住三星的酒店都没有这个要求！还有，房价是298，我订了两个房共一晚，酒店要求压金2000元！', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9755395650863647}, {'label': '好', 'score': 0.024460403248667717}]\n",
      "{'text': '住了几次，这次还特意带了朋友一起去入住，结果，酒店的早餐让我们太失望了，越来越差啊，九点去的时候吃的东西都没有什么了，以后我是不会再来了。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.970758318901062}, {'label': '好', 'score': 0.029241647571325302}]\n",
      "{'text': '酒店地理位置较偏，如无自驾车，不建议入住。酒店在装修设计规划方面并不能体现四星的标准，其实底子还是很不错的，却弄得有些蛮荒的感觉，如酒店主楼前后的草坪都未能很好的利用。酒店的服务员很滑稽，会用眼光注视客人，但却不会问好，那么还不如不注视。入住时，前台一位男生还在用扬州话聊电话，对客人不理不睬。房间的装修很单调，墙面上都是素色的墙纸。大面积的空处，却无一副装饰画，单调无比。特别是标间的21寸电视，实在小得有些搞笑。卫浴设施到都是科勒的，勉强过关。至于学经济型酒店的通透卫浴设计，相对四星酒店有些不伦不类吧。酒店的自助早餐，两天没有变换菜式，被好友不幸言中，呵呵。如果你不是一位苛刻的人，还是能接受这样的酒店的。只是离四星实在有些距离。哦，还有，酒店大厅进出的感应门，反应极端的迟钝，哈哈！', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9704573154449463}, {'label': '好', 'score': 0.029542623087763786}]\n",
      "{'text': '我们定的是2间高级标准间,住一个晚上,感觉不象4星酒店,3星差不多,房间的硬件一般,好多门上的漆都掉了,没有吹风机没有保险箱,大厅不论是服务员还是高级职员态度都很一般,到是2个老门童态度很好.双人床只给一个早餐,很惨.不过象这种小地方也就这样了,下次不会去住了,378元来说性价比不高.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9694874286651611}, {'label': '好', 'score': 0.030512556433677673}]\n",
      "{'text': '酒店的位置不错,面对漓江,但是房间内设施不好,洗面盆和淋浴的水笼头都漏水,房间地毯不仅不平整,看上去还挺脏,让人不舒服.中餐厅卫生状况不好,餐具不干净,苍蝇多.早餐以主食为主,没什么下饭的菜,牛奶是用奶粉冲的,管饱不管好!酒店客人团队多.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9690880179405212}, {'label': '好', 'score': 0.03091195784509182}]\n",
      "{'text': '交通还比较方便,价格相对便宜,但是设施有些陈旧,没有网络可上网,服务生的素质相对较低些,如果重新装修在这个位置应该还是不错.', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.033395443111658096}, {'label': '好', 'score': 0.9666045308113098}]\n",
      "{'text': '首先我说说洗手间的问题,之前看了网友说这里的卫生间很小不太留意,可是去到才真的发现卫生间真的太小了,我们住的是标双,卫生间大概只有2-3平方的样子,而厨房其实是没有用的,真的不知道建筑师是怎么设计的.花洒就在马桶的上面,转个身就会碰到马桶,洗澡要想马桶不湿简直是天方夜谈了!!然后就是关于房间的价格,156', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9648477435112}, {'label': '好', 'score': 0.03515230491757393}]\n",
      "{'text': '前台人员不但英语不好,普通话也不好.不过,大堂吧的服务人员很赞.', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.03719552233815193}, {'label': '好', 'score': 0.9628044366836548}]\n",
      "{'text': '九寨沟喜来登国际大酒店是五星级大酒店，价格不菲，尽管携程的价格已经便宜了许多，但是的确有点名不副实。主要有以下几点让人不是很满意：1、酒店号称在九寨沟沟口，但实际上距离沟口还有一公里半的距离。只是喜来登的广告牌确实屹立在沟口位置。2、酒店的娱乐设施比较不好，桌球、电玩、网吧聚集一室，空气不好，而且设备也少，不过，喜来登的客人也不多，可能也用不到很多的设备吧。3、酒店的自助早餐价格还是很贵的，但是品种实在是很少。4、酒店的大床间的床真的是很大，居然是双床间的两张大床拼成的，床的宽度可想而知，半夜起来要爬半天才能摸到床灯。5、这个酒店给人的感觉就是贵，价格绝对是五星级的，但是其他方面也就跟好点的四星级宾馆差不多吧。而且酒店周围是完全找不到吃饭的地方的，荒芜一片，所以，这也要减点分吧。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9627469778060913}, {'label': '好', 'score': 0.03725304827094078}]\n",
      "{'text': '枕头太低了不好睡，不过在驻马店这种地方算可以了', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.03801519423723221}, {'label': '好', 'score': 0.9619848728179932}]\n",
      "{'text': '酒店在西宁来说还是比较满意的,首先,地理位置不错,人口素质还不错.其次,房间设置虽然比较简单,但基本达到四星标准.第三,不满意的地方就是服务问题.各位先前入住酒店的朋友已经提到了,我需要补充的是,前台的女服务员还没有男服务生热情.基本不属于不会笑的或者是比较会耍NB的.按照对方理论,谁让我们是外地人呢,人家能给我们个地儿住就不错了.最后,我要说的是,早餐只有中餐,虽是自助,但基本没有办法评论,我只提一点,早餐的橙汁是热的,原来是用市场上早已绝迹的TANG果珍冲泡的.所以房间我给3分,环境给4分外,都是1分.', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.04082604870200157}, {'label': '好', 'score': 0.9591739177703857}]\n",
      "{'text': '我于6月1日再次入住,住的是1312房,首先价格由238元涨到278元,是整个乌鲁木齐酒店旺季都涨了,据说每年7月和8月乌鲁木齐酒店都还要涨,这也可以理解,毕竟就那么几个月可以赚钱,冬天都是零下20几度,人很少.但是我发现房间的迷你吧撤了,只有留了两瓶矿泉水.卫', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.04200242832303047}, {'label': '好', 'score': 0.9579975605010986}]\n",
      "{'text': '好像第二次入住了，这次的标间环境不好，房间感觉不台干净，电视机也不好', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9557867646217346}, {'label': '好', 'score': 0.04421317204833031}]\n",
      "{'text': '宾馆竟然不能提供网络调试服务，我做了一次兼职的网管，呵呵！很有面子，去得那天天气冷，刚开始有点不太适应，要空调遥控器，说现在不提供；要加被子，说没有，当时很郁闷，不过做了兼职网管之后很快就提供了这两样东西，很开心另外，前台太小，性价比不高补充点评2007年10月22日：顺便说一下，前台竟然不知道长途电话的收费标准', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.04561559855937958}, {'label': '好', 'score': 0.954384446144104}]\n",
      "{'text': '给父母订的~回来说房间远不及盛华的,早餐也不行.唯一好的就是在风景区内了~', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.045949164777994156}, {'label': '好', 'score': 0.9540507793426514}]\n",
      "{'text': '宾馆很豪华，周围环境很好，适合度假。但酒店服务很差。五星级宾馆的大床间竟然没有宽带。早餐也很一般。免费注册网站导航宾馆索引服务说明关于携程诚聘英才代理合作广告业务联系我们Copyright1999-2008,ctrip.com.allrightsreserved.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9518766403198242}, {'label': '好', 'score': 0.0481233112514019}]\n",
      "{'text': '感觉一般，就是各方面都一般，在三门峡这种地方住住还是可以的', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.050848186016082764}, {'label': '好', 'score': 0.949151873588562}]\n",
      "{'text': '房间还可以（我住的是二十一层），但空调不太好--温度不好调节以及噪音不小，淋浴水量也不是很大。另外就是酒店电梯太少了，只有两部可以用。每次都要等好长时间才能等到电梯。下次估计不会再住了', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9461601972579956}, {'label': '好', 'score': 0.053839776664972305}]\n",
      "{'text': '经常入住京伦酒店，感觉还不错。但是3月份去的一次，安排了一个最拐角的房间有一张双人床，服务人员说要是豪华间多交钱才能给大双人床，以后去北京会考虑入住别的酒店。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.05392439663410187}, {'label': '好', 'score': 0.9460755586624146}]\n",
      "{'text': '不知为何，成都的凯宾斯基饭店确实不能够与其他凯宾斯基饭店相提并论，硬件倒说不出有什么不妥，但软件却不敢恭维。checkin的时候，信用卡被他们告知有问题，居然是余额不足（这是绝对不可能发生的，应该是饭店的网络出了问题），好不容易在银行工作人员的协助下解决了。Checkout的时候，居然说我用了小吧台的物品，查来查去，又被告知是前一位客人使用的，记在我名下。所以，建议朋友们，如果对服务要求比较高，可能不是最佳选择。另外，这个酒店无论哪个房间，都比较吵。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9445892572402954}, {'label': '好', 'score': 0.05541079863905907}]\n",
      "{'text': '性价比一般，主要体现在早餐难以令人满意，希望增加花色品种。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.05583374202251434}, {'label': '好', 'score': 0.9441661834716797}]\n",
      "{'text': '前台服务态度挺好。但酒店设施较简单陈旧，感觉连二星的都比不上，房间隔音效果也不好，外面卡拉ok的声音听的清清楚楚，晚上要是失眠了可以听听歌。宾馆反馈2007年10月30日：尊敬的宾客：非常感谢您的光临及提出宝贵的意见，本酒店目前的房间设施设备是以简约时尚为前提，关于隔音改造工程正在完善中，相信我们会以更优质的服务和舒适的客房、便利的商务环境，迎接您的再次光临！', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.05960467457771301}, {'label': '好', 'score': 0.9403952956199646}]\n",
      "{'text': '房间里的设施有些老旧了，毛巾、浴巾、浴袍也都很旧。房间隔音很不好，本来以为在半上腰会很安静，结果却被下面卡拉OK还是夜总会的歌声吵得睡不着觉。唯一的优点是山上空气好。白天倒是很安静。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.938193142414093}, {'label': '好', 'score': 0.061806820333004}]\n",
      "{'text': '中餐厅的服务员有忽悠客人嫌疑，我们晚上9点到宾馆，上下跑了二回才找到中餐厅，我们一壶茶也没喝，也收了我们的茶费，更让人气愤的是，我们点的鳝鱼筒有异味，我们向服务员提出，她们态度很好，口头答应餐费减去，但到退房结账时，还是没有减去，因为我们要赶时间就没有和她们理论，但给我们留下的是她们的诚信不够。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9358622431755066}, {'label': '好', 'score': 0.06413768976926804}]\n",
      "{'text': '外观旧,停车场小,乱,还另外收钱,不过酒店还干净.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9325721859931946}, {'label': '好', 'score': 0.06742777675390244}]\n",
      "{'text': '7月中旬入住过一晚，说说感受。硬件条件和皇冠的牌子还是比较匹配的，但软件（服务）还差的很多。1.入住那天被安排进了一间高级间，洗澡的时候发现没有浴帘，结果弄的厕所满地都是水，打电话去问，告知：这种浴缸是给那些泡澡的人设计的。言外之意是不适合淋浴。洗手间内并没有另外的淋浴房。2.健身房内的跑步机的传送带很窄，跑步的时候经常担心会摔倒。健身房内的矿泉水要收15一瓶，水就是房间里免费的那种。据理力争了半天，把大堂经理都折腾上来才免费了。3.结账的时候钱都付完，发票也开完了，被告知还有上网费没有结清。就是那著名的11.5一小时的上网费。头回听说都结完帐了还要收钱的。4.门口出租车坐地起价。因为赶飞机，让门僮帮忙拦了一部出租车，车刚开出去没多远，司机就抬高价格，如果不接受他就不拉。据司机说是要给门僮好处费。因为赶飞机，只能付了冤枉钱。5.最后说说大堂。大堂搞了很多山山水水，的确是很漂亮，不过也成了蚊子的温床。在大堂久留一定会被蚊子咬的。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9317710399627686}, {'label': '好', 'score': 0.06822890043258667}]\n",
      "{'text': '还是房价贵了点，如果房价在200就可以了。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.0698661357164383}, {'label': '好', 'score': 0.9301339387893677}]\n",
      "{'text': '可以坐地铁8号线，在曲阜路下车出地铁就到了。西藏北路路口出。到对面就能找到国庆路。不过这个酒店的毛巾，浴巾相当的旧，而且还是黄色的那种，我都没有用过。还好只是住了一天。比较起来对面的晋元大酒店在这方面做的就好多了，旧是旧了点但是毛巾比较好，起码可以用。不过这个地方相对来说很安静。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.0709059089422226}, {'label': '好', 'score': 0.9290940165519714}]\n",
      "{'text': '推荐天目湖宾馆,各方面设置比这家好多了.值得推荐的是他们的餐厅还算过得去,鱼头还能吃吃.但是前台小姐的服务太差了。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.07284946739673615}, {'label': '好', 'score': 0.927150547504425}]\n",
      "{'text': '我是本周5晚上入住假日酒店的，订的是海景房。酒店的周边环境很一般，所谓的海景也就是一个码头，和我想象的还是有一定的差距。周边的旅游设施也不是很完善。所谓的网球场也是冷冷清清。酒店的中餐厅味道不错，但是点菜的小姐缺乏职业道德。写菜的时候已经明确告知我要去掉其中的一道名为东江豆腐煲的菜，但是上菜的时候还是上了。不知道该酒店是怎样对员工进行培训的，2个人能吃4道菜吗？？？事后餐厅的领班还阵阵有词，让人感觉星级酒店和大排档没有太大的区别。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9239619374275208}, {'label': '好', 'score': 0.07603804767131805}]\n",
      "{'text': '于其说是点评,不如说是投诉,2008年7月15日晚,我公司一行3人通过携程网预定入住市长大厦,作为广州服务业的知名宾馆,我们对该单位的软件,硬件和服务无可厚非,因为它的价格比起其他的宾馆也是不一般的,但有关该宾馆自定的口头条款用于实际的服务强加给入住客人时,使我们不得不对其星级的服务和档次表示怀疑.事情是这样的,当时一行三人有2位是日本客人,在晚间洗澡时导致入住房间的地毯浸湿,16日离店时由总台值班经理处理此事,提出按照宾馆规定要赔偿一天的营业损失620元,我本人作为客人对此有极大不满和看法:1.首先:赔偿620元的规定只是宾馆的前台人员口头说出并强加给客人,相关的书面规定条款我们没有看到!2.作为广州知名的5星级宾馆,客人入住后有水浸地毯的事实,但宾馆方面没有从自身寻找原因,只是值班经理说通过检查他们的排水系统的硬件没有问题,我给人认为,处理问题最讲究的是要有证据,如只是听从宾馆人员单方面的信口雌黄,能说明问题吗,作为服务行业,难道出了问题更多的是找出没有证据的理由来对客人强加责难和经济惩罚吗?这显然违背了该行业的存在初衷!3.疑问:之所以会有以上的投诉反馈,我们不禁要问:宾馆浴缸在正常的放水时即使有连续的水注入,浴缸上方的溢水孔同样也会及时地排出多余的水,怎么会有水流出呢?原因无非有2种:其一地漏不同或流淌缓慢导致积水溢出卫生间.其二溢水孔是否真的有溢水功效?4.现在的宾馆,诸多都是以自制的霸王条款来约束客人,甚至超越其权限对客人进行经济处罚,这本身就是对\"服务\"和\"星级\"的一种亵渎,试想,入住这么高档的酒店,排除极个别的因素外,有那位客人会没事去做这样无聊的事情让其水漫金山呢?况且,入住者还是50几岁的老人!5.最终由于我们赶路的原因,还是作了\"妥协\",交了罚款,离店而去,留给外方客人的是对广州市长大厦这种处理问题的方式和态度表示更多的无奈和遗憾,同时更多的是我们中国人对服务行业的国人(抛开政治因素)的这种做法提出反思,是否我们应该改一改了!要知道,简单的口头武断是不能作为评定事实的证据的,要以理服人,以德服人!6.目前为止,对此事我们还保留向有关部门投诉的权力!7.对于该酒店的软硬环境评价,我们还是以公正的心态去评判!毕竟,没有最好,只有更好嘛!', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9166452884674072}, {'label': '好', 'score': 0.08335466682910919}]\n",
      "{'text': '这家是我在太原住的性价比比较好的酒店,但是上次入住找服务员单独要了一床被子,气味极其不好,与酒店不相称,而且没有早餐,建议携程考虑和酒店协调一下.', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9144264459609985}, {'label': '好', 'score': 0.08557354658842087}]\n",
      "{'text': '酒店自诩准五星，入住后，让人大跌眼球。原本订的6日13至15日二晚住宿，由于飞机晚点，到达酒店已经是凌晨二时，没有门童，行李是自己提上台阶进大堂的。大堂的层面很低很压抑，装修陈旧而俗气，总台服务员自始至终没有微笑。问现在这个时候入住是否有优惠，她爱理不理以摇头代答。订的是毫华大床间，令人不可思议的是，这个所谓的豪华居然是这样的――电视机最多只有19寸，灯光昏暗，床硬硬的，没有供客人使用的纸袋，地毯很脏。特别是最多只有19寸的电视机，说准五星简直是一种欺诈了。于是决定天亮后就换到泰达美爵。退房时，居然又浪费了我近二十分钟。办完手续，也没有任何一个门童帮我推行李。看发票，盖的是部队招待所的章。原来这个所谓的准五星，居然是招待所！我百思不得其解，这种档次的酒店，怎么会得到一些客人这么高的评价。补充点评2008年6月25日：“1、您到店的时间已经超出您的预订时间，酒店仍然给您保留了房间，并且按照您预订的网络价格给予了优惠，而且免费为您升级到了豪华房间；2、您入住房间的电视机是21寸的液晶电视；3、客人需要购物袋可以向房务部或前台索取，我们会提供给客人......”――――一、我预订的是商务房，价格为558元，因为不喜欢商务房的装修风格，要求降格到豪华房。我这里保存着携程的订单，以及降格到豪华房后我支付的豪华房488元房价发票。我不知道贵酒店所称的“免费为您升级到了豪华房间”是什么意思。希望能看到解释。二、即便真如您所称，“电视机是21寸的液晶电视”，请告诉我，如此小屏的电视机，放在一家自称准五星标准的酒店的豪华房，是否合适？三、您提到“客人需要购物袋可以向房务部或前台索取”，这显然牵强了，若按照这种逻辑，是否可以延伸到客人需要卫浴用品可以向房务部或前台索取？若酒店真有“客人需要购物袋可以向房务部或前台索取”的惯例，那至少应该用文字的方式在床柜之类的地方明示吧？宾馆反馈2008年6月23日：尊敬的宾客：您好！非常感谢您把金海大酒店作为您大连之行的驿站，也非常感谢您对酒店提出的意见，对于您此行的不愉快我们深表歉意！在以后的工作中我们将加强酒店员工的培训，提高服务意识及服务质量！对于您以上提出的问题我们做略加解释，希望您能够理解！1、您到店的时间已经超出您的预订时间，酒店仍然给您保留了房间，并且按照您预订的网络价格给予了优惠，而且免费为您升级到了豪华房间；2、您入住房间的电视机是21寸的液晶电视；3、客人需要购物袋可以向房务部或前台索取，我们会提供给客人；4、酒店员工服务的不到位说明我们的管理还需要进一步加强。再一次感谢您所提出的意见，欢迎您能够再一次入住我们酒店！', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.08680667728185654}, {'label': '好', 'score': 0.9131932854652405}]\n",
      "{'text': '经携程定的浪漫情人夜度假产品，6月20日中午12点入住蜜月套房，中午12点30分到达酒店、办理好入住手续才被告知房间未搞卫生，需要一小时、问前台接待是否留电话给他，搞好卫生通知一声，得到冷淡的回答：一小时后自已来问吧！没办法只好在西餐厅苦苦的等待，等到1点30分到前台询问：另外一位接待的感到奇怪怎还没能给入住，打电话问后答复还需要20分钟才能搞好，1点50分终于可以入住了。进入房间感到有点热就打开空调、调到22度，冲个凉休息一下，睡了一会感到房间还是那么热，一看空调、调节器定的22度显示屋内温度28度，打电话到管家部、答应叫工程师过来看看，等了10分钟工程师来了，说了一句：不好意思，我们是中央空调，现在全部设定的温度是27-28度，晚上就会好点，真难受！这就是五星级酒店，晚上上半夜的温度是25度、早上8点钟再看是24度，大家想象一下，6月20日是《夏至》是全年最热的日子，住在这样的五星级宾馆是不是拿钱来受罪啊！酒店大堂是豪华，西餐厅的套餐是不错，可是前台的接待和酒店为了省电所设定的温度真的太差劲了，原定第二天入住豪华客房，也只能取消赳快离开了…', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.9076936841011047}, {'label': '好', 'score': 0.09230632334947586}]\n",
      "{'text': '升级之后的商务单人间A房间很不错，超大的床，睡起来很舒服。是从火车站对面的时代广场换过来的，所以相比而言，这里的环境也要好很多。在那边一路上都有人问我：“住宿不，小伙？”（小弟看起来好像年纪很小啊#_#）也要提一个不爽的事，尽管后来解决了，但还是得为后来的各位提个醒。预定的时候，携程上面的资料写着“商务单人间内配有电脑”，然后预定列表里有商务单人间A和商务单人间B两种。我就想当然地认为便宜的那种B型房也有电脑。（经过这次向携程咨询，携程上面的信息已经更正过来。）入住首先发现B型房没有。这是小事，除了这点，也推荐各位不要选择B型房。房间很小，基本相当于没有窗户，有一扇不透光的窗户，但是你基本不能打开。打开之后，首先眼前看到的是六楼的楼顶，然后楼顶上是几个卫星电视的大锅，一个哄哄响的中央空调。把窗户关紧，中央空调的声音也很清楚，估计半夜的时候会影响睡觉。这个房型是在七层，不知道是不是违规建的，很多东西都不正常，电梯只通到六层，要走一层楼梯才能上去，这一层好像也很少有人住。当然，后来携程和酒店的解决还是满意的：给升级到A型房。服务没太多接触。但是有一个比较好玩的，因为酒店二层是一家叫大连渔港的海鲜饭店，所以每到吃饭的时候，一层电梯口都站一排MM，看见有人来就热情地问你到几楼，并作势帮你按电梯，如果说到二层，则会一路陪伴你上去用餐；如果说其他客房楼层，就对你没啥兴趣了，伸出来按电梯的手也缩回去了。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.905161440372467}, {'label': '好', 'score': 0.09483852982521057}]\n",
      "{'text': '网上讲的房间是24平米，实际没有那么大。另外房的空调也不是很凉快!', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.893346905708313}, {'label': '好', 'score': 0.10665303468704224}]\n",
      "{'text': '环境还行。服务质量不高～～前台接待员缺乏礼貌用语，行李没有服务员运送，也没有导行的服务员。进了酒店要自己做所有的事，包括找自己的房间。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8779664039611816}, {'label': '好', 'score': 0.12203357368707657}]\n",
      "{'text': '介绍说酒店是座落于北四环的北苑路，结果晕我。该酒店位置偏僻，再走几步就是五环了，怎么会是四环？？第二天一早等半天也没有出租车来，只有走到大马路边去等，还是没有。冷得要命，最后没有办法，有一黑出租问我走不走，只有坐上车走了。房间还是不错得。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.12440355122089386}, {'label': '好', 'score': 0.8755964636802673}]\n",
      "{'text': '酒店设施不错，服务很好。但是交通不方便，出租车不好找。去朱家角要计双程。且酒店没有什么娱乐设施。晚上比较无聊。酒店靠近东方绿洲2号口。2号口里有出租自行车的地方，强烈建议不要去那里租车。车子很破，服务很差。且4：30就关门。过点就没办法还车，押金就算买它的破车！？可以到1号口或者在酒店里面租车。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8736889958381653}, {'label': '好', 'score': 0.12631092965602875}]\n",
      "{'text': '1,房间空调跟电扇一样，不制冷，反映三次服务员答应给看看最后也没来2，因为有时差，凌晨0点入住，说下午六点前退房算一天，结账时候硬说要中午12点退房，催我们离开3，没有服务意识补充点评2008年5月22日：这地方离市区远，价格在当地不算便宜。宾馆反馈2008年5月23日：首先感您所提到及的问题，其一、关于您入住房间空调不制冷问题，可能有部分房间的空调调试和加冷媒，美的空调公司正在实施。但客人反映问题后，服务员一直没有来解决反映出酒店服务中欠缺之处：1、缺乏感情服务2、缺乏服务的主动性，没能急客人所急、想客人所想。对此我们将在今天下午的培训课上，专门就服务意识的问题进行专项的培训，以后也将就此不定期的开展专题培训，以尽量避免这方面失误的发生。其二、新疆同内地是有时差的，按常规酒店房费的收取是按过夜房计算的，即过夜就按全天房费收取。您可查阅一下相关的行规。12点退房前询问是否继续延住是每个酒店都会例行的程序，我们绝没有催您离开的意思，因一些特殊的原因需晚一些退房，您可以提出来，我们会适当满足您的需求。最后感谢您选择入住如家北园春店。对您此次下榻酒店带来的不便致以真挚的歉意。您的点评象镜子一样折射出酒店在管理方面还存在疏漏。酒店将以此为鉴，杜绝此类事情的发生。期待您的再次光临。为了提高我们的服务意识，更好的为您及广大客户提供优质、有效的服务，请您继续关注我们，同时也希望各位携程的会员能够参与到监督我们服务的行列中。', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.1303446739912033}, {'label': '好', 'score': 0.8696553111076355}]\n",
      "{'text': '早餐有时8点结束，刷卡不方便，还要压现金，房间打扫不及时', 'label': '不好'}\n",
      "[{'label': '不好', 'score': 0.13231097161769867}, {'label': '好', 'score': 0.8676890730857849}]\n",
      "{'text': '环境很好，算得上度假胜地，带露台、电脑的房间很让人愉悦。服务真的很一般很一般，办入住手续的时候居然可以连钥匙牌都给错。我们订的是一间普通套房和一间景观标间，在标间的订单中还特别注明要带景观的（这好像是废话？结果事实证明一点都不废），总台给的房间是一间带露台的套房和一间不带露台的套房。所谓套房也就是多一个麻将室，因我们之前查到酒店自己的网站上写着“景观房有露天阳台”，我们以为朝北的客房没有露台所以做成了麻将室，也就没在意。然后晚上准备休息的时候，大堂副理过来敲门，说给错钥匙了，给的两间都是套房，要换一间标房。换给我们的是朝北不带露台的房间，还说这个区域的客房统称景观房，不是一定带露台的。我们请携程交涉，才换到一间朝南的。这里的服务人员态度都好奇怪，餐厅没有人领位，清扫工自顾自抢在客人前面出门，早上8点多服务员敲门问可不可以整理房间（双休日唉，请勿打扰灯亮着没看见？），见到客人微笑问好是不要指望的。选这个宾馆一个原因是冲着锦江的牌子，相信管理、服务会比较到位吧，结果很失望，硬件硬，软件软。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8664829134941101}, {'label': '好', 'score': 0.1335170716047287}]\n",
      "{'text': '不好的地方就是我们搞不明白这么差的兴安县城怎么会有那么好的酒店，呵呵，乐满地我们没有去游，可能是因为那里吧', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.862108051776886}, {'label': '好', 'score': 0.13789190351963043}]\n",
      "{'text': '酒店的设施和环境有五星的标准。但酒店的服务绝对没有同样的水准。我14点到酒店的，房间没有整理好。30分种上房间，依旧在整理中，期间得到的唯一答复是：五一客人多，来不及整理。没有任何其他的表示。补充点评2007年5月7日：和酒店高达1400的房费相比，其服务水准实在不能相比。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8620579838752747}, {'label': '好', 'score': 0.13794203102588654}]\n",
      "{'text': \"Excellentlocation!NexttoCiticSquareandoppositetoPlaza66.TheLine2metrostationiswithina3-minstroll.Theroomisslightlysmallerthanexpected.I'vestayedattheRegalia'sservicedapartmentinSuzhouonceforalowerpriceandmuchbiggerroom.There'sevennokitcenwareinthemini-kitchen.Reckonit'llbekindainconvenientforlong-termguests.Anywayit'snotabigdealtomeasIdon'tbothercooking.Choicesatbreakfastarelimited.Serviceisprettygoodthough.宾馆反馈2008年7月31日：ThankyouforreplyingtoCtripsfeedback,weappreciateallfeedbackasitmakesusawareofwhatourcustomersneedsandexpectationsare.Shouldyourequireanykitchenutensilsorequipment,pleasecallHousekeepingandwewilldoourutmosttomeetyourneeds.ThankyouagainforyourfeedbackandwehopetoseeyoubacksoonatCentralViewSuites.\", 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8580154776573181}, {'label': '好', 'score': 0.14198453724384308}]\n",
      "{'text': '购物选择入住是非常方便，酒店就连着海港城，但是房间一般，设施也很陈旧，早餐也非常一般，个人认为，香港最好的酒店早餐是数码港艾美酒店的。', 'label': '好'}\n",
      "[{'label': '不好', 'score': 0.8525311350822449}, {'label': '好', 'score': 0.14746886491775513}]\n"
     ]
    }
   ],
   "source": [
    "for ele in cl_both:\n",
    "    print(list_test[ele])\n",
    "    print(list_scores[ele])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}